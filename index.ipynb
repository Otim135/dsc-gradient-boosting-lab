{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll learn how to use both Adaboost and Gradient Boosting classifiers from scikit-learn!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Use AdaBoost to make predictions on a dataset \n",
    "- Use Gradient Boosting to make predictions on a dataset \n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lab, we'll learn how to use boosting algorithms to make classifications on the [Pima Indians Dataset](http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.names). You will find the data stored in the file `'pima-indians-diabetes.csv'`. Our goal is to use boosting algorithms to determine whether a person has diabetes. Let's get started!\n",
    "\n",
    "We'll begin by importing everything we need for this lab. Run cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use Pandas to import the data stored in `'pima-indians-diabetes.csv'` and store it in a DataFrame. Print the first five rows to inspect the data we've imported and ensure everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "Diabetes = (\"pima-indians-diabetes.csv\")\n",
    "df = pd.read_csv(Diabetes)\n",
    "\n",
    "# Display the first few rows to inspect the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, exploration, and preprocessing\n",
    "\n",
    "The target we're trying to predict is the `'Outcome'` column. A `1` denotes a patient with diabetes. \n",
    "\n",
    "By now, you're quite familiar with exploring and preprocessing a dataset.  \n",
    "\n",
    "In the following cells:\n",
    "\n",
    "* Check for missing values and deal with them as you see fit (if any exist) \n",
    "* Count the number of patients with and without diabetes in this dataset \n",
    "* Store the target column in a separate variable and remove it from the dataset\n",
    "* Split the dataset into training and test sets, with a `test_size` of 0.25 and a `random_state` of 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "missing_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with diabetes: 268\n",
      "Number of patients without diabetes: 500\n"
     ]
    }
   ],
   "source": [
    "# Count the number of patients with and without diabetes\n",
    "diabetes_counts = df['Outcome'].value_counts()\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of patients with diabetes:\", diabetes_counts.get(1, 0))\n",
    "print(\"Number of patients without diabetes:\", diabetes_counts.get(0, 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Outcome']\n",
    "df = pd.read_csv(Diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(type(df))  # This will show the type of `df`\n",
    "print(df)        # This will display the content of `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (X_train): (614, 8)\n",
      "Test set size (X_test): (154, 8)\n",
      "Training target size (y_train): (614,)\n",
      "Test target size (y_test): (154,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['Outcome'])  # Drop the Outcome column to keep only features\n",
    "y = df['Outcome']                # Target variable\n",
    "\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the sizes of the splits for verification\n",
    "print(\"Training set size (X_train):\", X_train.shape)\n",
    "print(\"Test set size (X_test):\", X_test.shape)\n",
    "print(\"Training target size (y_train):\", y_train.shape)\n",
    "print(\"Test target size (y_test):\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "Now that we've explored the dataset, we're ready to fit some models!\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Instantiate an `AdaBoostClassifier` (set the `random_state` for 42)\n",
    "* Instantiate a `GradientBoostingClassifer` (set the `random_state` for 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier instantiated: AdaBoostClassifier(random_state=42)\n",
      "GradientBoostingClassifier instantiated: GradientBoostingClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Instantiate an AdaBoostClassifier\n",
    "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Instantiate a GradientBoostingClassifier\n",
    "gbt_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Display the instantiated models\n",
    "print(\"AdaBoostClassifier instantiated:\", adaboost_clf)\n",
    "print(\"GradientBoostingClassifier instantiated:\", gbt_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit the training data to both the classifiers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fit AdaBoostClassifier\n",
    "# Fit the AdaBoostClassifier to the training data\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "print(\"AdaBoostClassifier trained successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fit GradientBoostingClassifier\n",
    "# Fit the GradientBoostingClassifier to the training data\n",
    "gbt_clf.fit(X_train, y_train)\n",
    "print(\"GradientBoostingClassifier trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use these models to predict labels on both the training and test sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost model predictions\n",
    "adaboost_train_preds = adaboost_clf.predict(X_train)  # Predictions on training set\n",
    "adaboost_test_preds = adaboost_clf.predict(X_test)   # Predictions on test set\n",
    "\n",
    "# GradientBoosting model predictions\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train)       # Predictions on training set\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test)         # Predictions on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, complete the following function and use it to calculate the accuracy and f1-score for each model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.84\n",
      "F1-Score: 0.75\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.94\n",
      "F1-Score: 0.91\n",
      "\n",
      "Testing Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.73\n",
      "F1-Score: 0.63\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.75\n",
      "F1-Score: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define the function to display accuracy and F1-score\n",
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)  # Calculate accuracy\n",
    "    f1 = f1_score(true, preds)        # Calculate F1-score\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    print(\"F1-Score: {:.2f}\".format(f1))\n",
    "\n",
    "# Display training metrics\n",
    "print(\"Training Metrics\")\n",
    "display_acc_and_f1_score(y_train, adaboost_train_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "\n",
    "# Display testing metrics\n",
    "print(\"Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test, adaboost_test_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go one step further and create a confusion matrix and classification report for each. Do so in the cell below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: AdaBoost\n",
      "[[78 21]\n",
      " [20 35]]\n",
      "\n",
      "Classification Report: AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79        99\n",
      "           1       0.62      0.64      0.63        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.71      0.71       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_confusion_matrix = confusion_matrix(y_test, adaboost_test_preds)\n",
    "print(\"Confusion Matrix: AdaBoost\")\n",
    "print(adaboost_confusion_matrix)\n",
    "print(\"\\nClassification Report: AdaBoost\")\n",
    "print(classification_report(y_test, adaboost_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: Gradient Boosting\n",
      "[[78 21]\n",
      " [18 37]]\n",
      "\n",
      "Classification Report: Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        99\n",
      "           1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test, gbt_clf_test_preds)\n",
    "print(\"Confusion Matrix: Gradient Boosting\")\n",
    "print(gbt_confusion_matrix)\n",
    "print(\"\\nClassification Report: Gradient Boosting\")\n",
    "print(classification_report(y_test, gbt_clf_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** How did the models perform? Interpret the evaluation metrics above to answer this question.\n",
    "\n",
    "Write your answer below this line:\n",
    "_______________________________________________________________________________________________________________________________\n",
    "The models performed as follows:\n",
    "\n",
    "AdaBoost Classifier:\n",
    "\n",
    "Accuracy: 73%, meaning the model correctly predicted outcomes for 73% of the test samples.\n",
    "Precision for Class 1 (Diabetes): 62%, indicating that out of all the instances predicted as diabetes, 62% were correct.\n",
    "Recall for Class 1 (Diabetes): 64%, meaning the model correctly identified 64% of all actual diabetes cases.\n",
    "F1-Score for Class 1: 63%, showing a balance between precision and recall.\n",
    "Confusion Matrix:\n",
    "20 false negatives (diabetes cases incorrectly predicted as non-diabetes).\n",
    "21 false positives (non-diabetes cases incorrectly predicted as diabetes).\n",
    "Conclusion: The model is moderately effective but struggles to achieve high precision and recall for identifying diabetes cases.\n",
    "Gradient Boosting Classifier:\n",
    "\n",
    "Accuracy: 75%, slightly better than AdaBoost.\n",
    "Precision for Class 1 (Diabetes): 64%, a slight improvement over AdaBoost.\n",
    "Recall for Class 1 (Diabetes): 67%, indicating it identified 67% of all diabetes cases.\n",
    "F1-Score for Class 1: 65%, showing improved balance between precision and recall compared to AdaBoost.\n",
    "Confusion Matrix:\n",
    "18 false negatives, fewer than AdaBoost.\n",
    "21 false positives, the same as AdaBoost.\n",
    "Conclusion: Gradient Boosting outperforms AdaBoost slightly in terms of accuracy, precision, and recall. It is better at reducing false negatives, which is critical in medical contexts like diabetes prediction.\n",
    "\n",
    " \n",
    " \n",
    "As a final performance check, let's calculate the 5-fold cross-validated score for each model! \n",
    "\n",
    "Recall that to compute the cross-validation score, we need to pass in:\n",
    "\n",
    "* A classifier\n",
    "* All training data\n",
    "* All labels\n",
    "* The number of folds we want in our cross-validation score  \n",
    "\n",
    "Since we're computing cross-validation score, we'll want to pass in the entire dataset, as well as all of the labels. \n",
    "\n",
    "In the cells below, compute the mean cross validation score for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Cross-Validation Mean Score: 0.7631270690094218\n",
      "Gradient Boosting Cross-Validation Mean Score: 0.7591715474068416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calculate cross-validation score for AdaBoost\n",
    "adaboost_cv_scores = cross_val_score(adaboost_clf, X, y, cv=5)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", adaboost_cv_scores.mean())\n",
    "\n",
    "# Calculate cross-validation score for Gradient Boosting\n",
    "gbt_cv_scores = cross_val_score(gbt_clf, X, y, cv=5)\n",
    "print(\"Gradient Boosting Cross-Validation Mean Score:\", gbt_cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models didn't do poorly, but we could probably do a bit better by tuning some of the important parameters such as the **_Learning Rate_**. \n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we learned how to use scikit-learn's implementations of popular boosting algorithms such as AdaBoost and Gradient Boosted Trees to make classification predictions on a real-world dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
